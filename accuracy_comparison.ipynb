{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Model\n",
    "\n",
    "### 3 New Chemistries\n",
    "\n",
    "Now that we have a random forest model in place, the next course of action is to measure the effectiveness of the model with 3 additional terminal group systems that were not included in any training or testing of the various models.\n",
    "\n",
    "These systems were then ran under similar conditions as the previous monolayer systems, and the coefficient of friction and  adhesion force were measured in the same manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Terminal Groups\n",
    "\n",
    "1. Toluene\n",
    "1. Phenol\n",
    "1. Difluoromethyl\n",
    "\n",
    "#### SMILES\n",
    "| Terminal Group | SMILES (H-terminated) | SMILES (CH3-terminated) |\n",
    "|------|------|------|\n",
    "| Toluene | Cc1ccccc1 | Cc1ccc(C)cc1 |\n",
    "| Phenol | c1ccc(cc1)O | Cc1ccc(cc1)O |\n",
    "| Difluoromethyl | FCF | FC(F)C |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the proper packages\n",
    "\n",
    "In this notebook, edits were made to the random forest model to allow it to be importable.\n",
    "\n",
    "To access that version, checkout the `accuracy_test` branch of the [random forest terminal group project](https://github.com/PTC-CMC/random_forest_tg.git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import signac\n",
    "import atools_ml\n",
    "import atools\n",
    "import copy\n",
    "import rf\n",
    "from pprint import pprint as pprint\n",
    "\n",
    "pd.set_option('display.float_format', '{:1.4g}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy version:\\t\\t{}\".format(np.version.full_version))\n",
    "print(\"pandas version:\\t\\t{}\".format(pd.__version__))\n",
    "print(\"matplotlib version:\\t{}\".format(matplotlib.__version__))\n",
    "print(\"seaborn version:\\t{}\".format(sns.__version__))\n",
    "print(\"signac version:\\t\\t{}\".format(signac.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data repositories should be located one level above this Jupyter notebook\n",
    "\n",
    "first_screening_proj = signac.get_project(root=\"../terminal_group_screening/\")\n",
    "first_mixed_screening_proj = signac.get_project(root=\"../terminal_groups_mixed/\")\n",
    "uniq_smiles = set()\n",
    "\n",
    "# grab all the smiles strings and filter out the repeats\n",
    "for job in old_screening_proj:\n",
    "    uniq_smiles.add((job.sp['terminal_group'], job.doc['h-smiles'], job.doc['ch3-smiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(uniq_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the smiles strings\n",
    "new_smiles_dict = dict()\n",
    "first_smiles_dict = dict()\n",
    "\n",
    "for group in uniq_smiles:\n",
    "    first_smiles_dict[group[0]] = [group[1], group[2]]\n",
    "\n",
    "new_smiles_dict['toluene'] =   [\"Cc1ccccc1\", \"Cc1ccc(C)cc1\"]\n",
    "\n",
    "new_smiles_dict['phenol'] = [\"c1ccc(cc1)O\", \"Cc1ccc(cc1)O\"]\n",
    "\n",
    "new_smiles_dict['difluoromethyl'] = [\"FCF\", \"FC(F)C\"]\n",
    "\n",
    "pprint(first_smiles_dict)\n",
    "pprint(new_smiles_dict)\n",
    "print()\n",
    "# merge the two dicts\n",
    "new_smiles_dict.update(first_smiles_dict)\n",
    "pprint(new_smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert the relational dictionary so smiles strings can be linked to their string name\n",
    "\n",
    "from collections import defaultdict\n",
    "my_inverted_dict = defaultdict(list)\n",
    "{my_inverted_dict[v[0]].append(k) for k, v in new_smiles_dict.items()}\n",
    "{my_inverted_dict[v[1]].append(k) for k, v in new_smiles_dict.items()}\n",
    "pprint(my_inverted_dict)\n",
    "\n",
    "# test that this prints out 'acetyl'\n",
    "print(my_inverted_dict['C(=O)C'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the signac project for the 3 new chemistries with identical top and bottom monolayers\n",
    "new_terminal_project = signac.get_project(root=\"../terminal_group_screening_accuracy_test\")\n",
    "\n",
    "# load in signac project for the 3 new chemistries with non-identical top and bottom monolayers\n",
    "test_new_old_project = signac.get_project(root=\"../terminal_group_mixed_original_16_new_3/\")\n",
    "\n",
    "pprint(first_smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of the 3 new chemistries with identical monolayers\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "data_new = []\n",
    "for job in new_terminal_project:\n",
    "    if \"COF\" in job.document and \"intercept\" in job.document:\n",
    "        data_new.append(\n",
    "                        {'Terminal Group': job.sp['terminal_groups'][0],\n",
    "                         'COF': job.doc['COF'],\n",
    "                         'intercept': job.doc['intercept'],\n",
    "                         'SMILES-H': new_smiles_dict[job.sp['terminal_groups'][0]][0],}\n",
    "                        )\n",
    "\n",
    "df_new = pd.DataFrame(data_new)\n",
    "df_new['COF'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of the 3 new chemistries with non-identical top and bottom monolayers\n",
    "\n",
    "df_new_old = pd.DataFrame()\n",
    "data_new_old = []\n",
    "for job in test_new_old_project:\n",
    "    if \"COF\" in job.document and \"intercept\" in job.document:\n",
    "        data_new_old.append({\n",
    "                             'Terminal Group 1': job.sp['terminal_groups'][0],\n",
    "                             'Terminal Group 2': job.sp['terminal_groups'][1],\n",
    "                             'COF': job.doc['COF'],\n",
    "                             'intercept': job.doc['intercept'],\n",
    "                             'SMILES-1-H': new_smiles_dict[job.sp['terminal_groups'][0]][0],\n",
    "                             'SMILES-2-H': new_smiles_dict[job.sp['terminal_groups'][1]][0],\n",
    "                             }\n",
    "                             )        \n",
    "df_new_old = pd.DataFrame(data_new_old)\n",
    "df_new_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the tribological data from the original studies (16 termini)\n",
    "\n",
    "data_old_mixed= []\n",
    "for job in old_mixed_screening_proj:\n",
    "    if \"COF\" in job.document and \"intercept\" in job.document and 'S2_bottom' in job.document and 'S2_top' in job.document:\n",
    "        data_old_mixed.append({'Terminal Group 1': job.sp['terminal_groups'][0],\n",
    "                         'Terminal Group 2': job.sp['terminal_groups'][1],\n",
    "                         'COF': job.doc['COF'],\n",
    "                         'intercept': job.doc['intercept'],\n",
    "                         'S2_bottom_5nN': job.doc['S2_bottom']['5nN'],\n",
    "                         'S2_bottom_15nN': job.doc['S2_bottom']['15nN'],\n",
    "                         'S2_bottom_25nN': job.doc['S2_bottom']['25nN'],\n",
    "                         'S2_top_5nN': job.doc['S2_top']['5nN'],\n",
    "                         'S2_top_15nN': job.doc['S2_top']['15nN'],\n",
    "                         'S2_top_25nN': job.doc['S2_top']['25nN'],\n",
    "                         'SMILES-1-H': new_smiles_dict[job.sp['terminal_groups'][0]][0],\n",
    "                         'SMILES-2-H': new_smiles_dict[job.sp['terminal_groups'][1]][0]})\n",
    "df_old_mixed = pd.DataFrame(data_old_mixed)\n",
    "df_old_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to generate a csv version of this dataframe\n",
    "\n",
    "# df_new.to_csv(\"./new_3_self.csv\")\n",
    "# df_new.sort_values(by=\"Terminal Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to generate a csv version of this dataframe\n",
    "\n",
    "# df_new_old.to_csv(\"./mixed_original_new3.csv\")\n",
    "# df_new_old.sort_values(by=\"Terminal Group 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old_mixed = pd.DataFrame(data_new_old, columns=[\"Terminal Group 1\", \"Terminal Group 2\", \"COF\", \"F0\", \"SMILES_H_1\", \"SMILES_H_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this to generate a summary of the prediction of the 5 models for toluene\n",
    "\n",
    "# #             SMILES2='C[C]=O',\n",
    "\n",
    "# summary_stat_cof = []\n",
    "# summary_stat_intercept = []\n",
    "# for seed in [43, 0, 1, 2, 3]:\n",
    "    \n",
    "#     a = rf.predict(SMILES1=new_smiles_dict['toluene'][0],\n",
    "#                SMILES2=new_smiles_dict['toluene'][0],\n",
    "#                path_to_data=\".\",\n",
    "#                random_seed=seed,\n",
    "#                vary_descriptors=False,\n",
    "#                vary_significant=False,\n",
    "#                barcode_seed=123,\n",
    "#                feature_cluster_json_location=\"../random_forest_tg/\")\n",
    "#     summary_stat_cof.append(a['COF'])\n",
    "#     summary_stat_intercept.append(a['intercept'])\n",
    "# print(summary_stat_cof, summary_stat_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary information from the previous cell\n",
    "\n",
    "# summary_data = []\n",
    "# # print('COF')\n",
    "# # print(np.mean(summary_stat_cof, dtype=np.float64))\n",
    "# # print(np.std(summary_stat_cof, dtype=np.float64))\n",
    "# # print(np.mean(summary_stat_cof), \" +- \",np.std(summary_stat_cof))\n",
    "\n",
    "\n",
    "# # print(\"Intercept\")\n",
    "# # print(np.mean(summary_stat_intercept, dtype=np.float64))\n",
    "# # print(np.std(summary_stat_intercept, dtype=np.float64))\n",
    "# # print(np.mean(summary_stat_intercept), \" +- \",np.std(summary_stat_intercept))\n",
    "\n",
    "# cof_pred_mean = np.mean(summary_stat_cof, dtype=np.float64)\n",
    "# cof_pred_std = np.std(summary_stat_cof, dtype=np.float64)\n",
    "\n",
    "# f_o_pred_mean = np.mean(summary_stat_intercept, dtype=np.float64)\n",
    "# f_o_pred_std = np.std(summary_stat_intercept, dtype=np.float64)\n",
    "\n",
    "# calc_mean = df_new[(df_new['Terminal Group'] == \"toluene\") & (df_new['Terminal Group'] == \"toluene\") ].describe().loc[['mean']]\n",
    "# calc_std = df_new[(df_new['Terminal Group'] == \"toluene\") & (df_new['Terminal Group'] == \"toluene\") ].describe().loc[['std']]\n",
    "\n",
    "\n",
    "# #calc_mean = df_new_old[(df_new_old['Terminal Group 1'] == \"pyrrole\") & (df_new_old['Terminal Group 2'] == \"toluene\") ].describe().loc[['mean']]\n",
    "# #calc_std = df_new_old[(df_new_old['Terminal Group 1'] == \"pyrrole\") & (df_new_old['Terminal Group 2'] == \"toluene\") ].describe().loc[['std']]\n",
    "\n",
    "# summary_data = np.asarray([[cof_pred_mean, calc_mean['COF'], f_o_pred_mean, calc_mean['intercept']],[cof_pred_std, calc_std.COF, f_o_pred_std, calc_std.intercept]], dtype=np.float64)\n",
    "# print(summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary tables for tribilogical properties based on chain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data is now in csv files for easier consumption\n",
    "\n",
    "# import numpy as np\n",
    "# def gen_summary_tribo(project):\n",
    "#     df_index = pd.DataFrame(project.index())\n",
    "#     df_index = df_index.set_index(['_id'])\n",
    "#     statepoints = {doc['_id']: doc['statepoint'] for doc in project.index()}\n",
    "#     df = pd.DataFrame(statepoints).T.join(df_index)\n",
    "#     chainlengths = df.chainlength.unique()\n",
    "#     chainlengths.sort()\n",
    "#     terminal_groups = df.terminal_group.unique()\n",
    "#     terminal_groups.sort()\n",
    "#     n_groups = len(terminal_groups)\n",
    "    \n",
    "#     # COF\n",
    "#     summary_cof_list = []\n",
    "#     for i, terminal_group in enumerate(terminal_groups.tolist()):\n",
    "#         cof = [df[(df.chainlength==chainlength) &\n",
    "#                   (df.terminal_group==terminal_group)].COF.mean()\n",
    "#                for chainlength in chainlengths]\n",
    "#         cof_err = [df[(df.chainlength==chainlength) &\n",
    "#                       (df.terminal_group==terminal_group)].COF.std()\n",
    "#                    for chainlength in chainlengths]\n",
    "\n",
    "#         dict_1 = {\n",
    "#             'System': str(terminal_group + ' - ' + terminal_group),\n",
    "#             'COF: {} carbons'.format(chainlengths[0]): cof[0],\n",
    "#             'COF: {} carbons'.format(chainlengths[1]): cof[1],\n",
    "#             'COF: {} carbons'.format(chainlengths[2]): cof[2],\n",
    "#             'COF: {} carbons'.format(chainlengths[3]): cof[3],\n",
    "#             'COF: {} carbons'.format(chainlengths[4]): cof[4],\n",
    "#             'COF Err: {} carbons'.format(chainlengths[0]): cof_err[0],\n",
    "#             'COF Err: {} carbons'.format(chainlengths[1]): cof_err[1],\n",
    "#             'COF Err: {} carbons'.format(chainlengths[2]): cof_err[2],\n",
    "#             'COF Err: {} carbons'.format(chainlengths[3]): cof_err[3],\n",
    "#             'COF Err: {} carbons'.format(chainlengths[4]): cof_err[4],\n",
    "            \n",
    "#         }\n",
    "#         summary_cof_list.append(dict_1)\n",
    "#     summary_cof_df = pd.DataFrame(summary_cof_list)\n",
    "#     cols = list(summary_cof_df.columns)\n",
    "#     cols = ['System', 'COF: 5 carbons', 'COF: 8 carbons',\n",
    "#             'COF: 11 carbons', 'COF: 14 carbons', 'COF: 17 carbons',\n",
    "#             'COF Err: 5 carbons', 'COF Err: 8 carbons',\n",
    "#             'COF Err: 11 carbons', 'COF Err: 14 carbons', 'COF Err: 17 carbons',\n",
    "#            ]\n",
    "#     summary_cof_df = summary_cof_df[cols]\n",
    "    \n",
    "#     #print(summary_cof_df)\n",
    "#     summary_cof_df.to_csv(\"same_terminal_groups_cof_summary.csv\")\n",
    "#     summary_cof_df.to_html(\"same_terminal_groups_cof_summary.html\")\n",
    "\n",
    "\n",
    "#     # adhesion\n",
    "#     summary_adhesion_list = []\n",
    "#     for i, terminal_group in enumerate(terminal_groups):\n",
    "#         intercept = [df[(df.chainlength==chainlength) &\n",
    "#                         (df.terminal_group==terminal_group)].intercept.mean()\n",
    "#                      for chainlength in chainlengths]\n",
    "#         intercept_err = [df[(df.chainlength==chainlength) &\n",
    "#                             (df.terminal_group==terminal_group)].intercept.std()\n",
    "#                          for chainlength in chainlengths]\n",
    "#         dict_1 = {\n",
    "#             'System': str(terminal_group + ' - ' + terminal_group),\n",
    "#             'F0: {} carbons'.format(chainlengths[0]): intercept[0],\n",
    "#             'F0: {} carbons'.format(chainlengths[1]): intercept[1],\n",
    "#             'F0: {} carbons'.format(chainlengths[2]): intercept[2],\n",
    "#             'F0: {} carbons'.format(chainlengths[3]): intercept[3],\n",
    "#             'F0: {} carbons'.format(chainlengths[4]): intercept[4],\n",
    "#             'F0 Err: {} carbons'.format(chainlengths[0]): intercept_err[0],\n",
    "#             'F0 Err: {} carbons'.format(chainlengths[1]): intercept_err[1],\n",
    "#             'F0 Err: {} carbons'.format(chainlengths[2]): intercept_err[2],\n",
    "#             'F0 Err: {} carbons'.format(chainlengths[3]): intercept_err[3],\n",
    "#             'F0 Err: {} carbons'.format(chainlengths[4]): intercept_err[4],\n",
    "#         }\n",
    "#         summary_adhesion_list.append(dict_1)\n",
    "#     summary_adhesion_df = pd.DataFrame(summary_adhesion_list)\n",
    "#     cols = list(summary_adhesion_df.columns)\n",
    "#     cols = ['System', 'F0: 5 carbons', 'F0: 8 carbons',\n",
    "#             'F0: 11 carbons', 'F0: 14 carbons', 'F0: 17 carbons',\n",
    "#             'F0 Err: 5 carbons', 'F0 Err: 8 carbons',\n",
    "#             'F0 Err: 11 carbons', 'F0 Err: 14 carbons', 'F0 Err: 17 carbons',]\n",
    "#     summary_adhesion_df = summary_adhesion_df[cols]\n",
    "    \n",
    "#     #print(summary_adhesion_df)\n",
    "#     summary_adhesion_df.to_csv(\"same_terminal_groups_adhesion_summary.csv\")\n",
    "#     summary_adhesion_df.to_html(\"same_terminal_groups_adhesion_summary.html\")\n",
    "    \n",
    "\n",
    "#     # nematic Order (S2) 5nN\n",
    "#     summary_nematic_5nN_list = []\n",
    "#     for i, terminal_group in enumerate(terminal_groups):\n",
    "#         nematic = []\n",
    "#         nematic_err = []\n",
    "\n",
    "#         nematic_list = [df[(df.chainlength==chainlength) &\n",
    "#                         (df.terminal_group==terminal_group)].S2\n",
    "#                      for chainlength in chainlengths]\n",
    "#         for chain_length_grouping in nematic_list:\n",
    "#             nematic.append(np.mean([i['5nN'] for i in chain_length_grouping]))\n",
    "#             nematic_err.append(np.std([i['5nN'] for i in chain_length_grouping]))\n",
    "#         dict_1 = {\n",
    "#             'System': str(terminal_group + ' - ' + terminal_group),\n",
    "#             'S2: {} carbons'.format(chainlengths[0]): nematic[0],\n",
    "#             'S2: {} carbons'.format(chainlengths[1]): nematic[1],\n",
    "#             'S2: {} carbons'.format(chainlengths[2]): nematic[2],\n",
    "#             'S2: {} carbons'.format(chainlengths[3]): nematic[3],\n",
    "#             'S2: {} carbons'.format(chainlengths[4]): nematic[4],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[0]): nematic_err[0],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[1]): nematic_err[1],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[2]): nematic_err[2],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[3]): nematic_err[3],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[4]): nematic_err[4],\n",
    "#         }\n",
    "#         summary_nematic_5nN_list.append(dict_1)\n",
    "#     summary_nematic_5nN_df = pd.DataFrame(summary_nematic_5nN_list)\n",
    "#     cols = list(summary_nematic_5nN_df.columns)\n",
    "#     cols = ['System', 'S2: 5 carbons', 'S2: 8 carbons',\n",
    "#             'S2: 11 carbons', 'S2: 14 carbons', 'S2: 17 carbons',\n",
    "#             'S2 Err: 5 carbons', 'S2 Err: 8 carbons',\n",
    "#             'S2 Err: 11 carbons', 'S2 Err: 14 carbons', 'S2 Err: 17 carbons']\n",
    "#     summary_nematic_5nN_df = summary_nematic_5nN_df[cols]\n",
    "    \n",
    "#     #print(summary_adhesion_df)\n",
    "#     summary_nematic_5nN_df.to_csv(\"same_terminal_groups_5nN_nematic_summary.csv\")\n",
    "#     summary_nematic_5nN_df.to_html(\"same_terminal_groups_5nN_nematic_summary.html\")\n",
    "#     print(summary_nematic_5nN_df)\n",
    "\n",
    "#     # nematic Order (S2) 15nN\n",
    "#     summary_nematic_15nN_list = []\n",
    "#     for i, terminal_group in enumerate(terminal_groups):\n",
    "#         nematic = []\n",
    "#         nematic_err = []\n",
    "\n",
    "#         nematic_list = [df[(df.chainlength==chainlength) &\n",
    "#                         (df.terminal_group==terminal_group)].S2\n",
    "#                      for chainlength in chainlengths]\n",
    "#         for chain_length_grouping in nematic_list:\n",
    "#             nematic.append(np.mean([i['15nN'] for i in chain_length_grouping]))\n",
    "#             nematic_err.append(np.std([i['15nN'] for i in chain_length_grouping]))\n",
    "#         dict_1 = {\n",
    "#             'System': str(terminal_group + ' - ' + terminal_group),\n",
    "#             'S2: {} carbons'.format(chainlengths[0]): nematic[0],\n",
    "#             'S2: {} carbons'.format(chainlengths[1]): nematic[1],\n",
    "#             'S2: {} carbons'.format(chainlengths[2]): nematic[2],\n",
    "#             'S2: {} carbons'.format(chainlengths[3]): nematic[3],\n",
    "#             'S2: {} carbons'.format(chainlengths[4]): nematic[4],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[0]): nematic_err[0],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[1]): nematic_err[1],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[2]): nematic_err[2],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[3]): nematic_err[3],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[4]): nematic_err[4],\n",
    "#         }\n",
    "#         summary_nematic_15nN_list.append(dict_1)\n",
    "#     summary_nematic_15nN_df = pd.DataFrame(summary_nematic_15nN_list)\n",
    "#     cols = list(summary_nematic_15nN_df.columns)\n",
    "#     cols = ['System', 'S2: 5 carbons', 'S2: 8 carbons',\n",
    "#             'S2: 11 carbons', 'S2: 14 carbons', 'S2: 17 carbons',\n",
    "#             'S2 Err: 5 carbons', 'S2 Err: 8 carbons',\n",
    "#             'S2 Err: 11 carbons', 'S2 Err: 14 carbons', 'S2 Err: 17 carbons']\n",
    "#     summary_nematic_15nN_df = summary_nematic_15nN_df[cols]\n",
    "    \n",
    "#     #print(summary_adhesion_df)\n",
    "#     summary_nematic_15nN_df.to_csv(\"same_terminal_groups_15nN_nematic_summary.csv\")\n",
    "#     summary_nematic_15nN_df.to_html(\"same_terminal_groups_15nN_nematic_summary.html\")\n",
    "#     print(summary_nematic_15nN_df)\n",
    "\n",
    "#     # nematic Order (S2) 25nN\n",
    "#     summary_nematic_25nN_list = []\n",
    "#     for i, terminal_group in enumerate(terminal_groups):\n",
    "#         nematic = []\n",
    "#         nematic_err = []\n",
    "\n",
    "#         nematic_list = [df[(df.chainlength==chainlength) &\n",
    "#                         (df.terminal_group==terminal_group)].S2\n",
    "#                      for chainlength in chainlengths]\n",
    "#         for chain_length_grouping in nematic_list:\n",
    "#             nematic.append(np.mean([i['25nN'] for i in chain_length_grouping]))\n",
    "#             nematic_err.append(np.std([i['25nN'] for i in chain_length_grouping]))\n",
    "#         dict_1 = {\n",
    "#             'System': str(terminal_group + ' - ' + terminal_group),\n",
    "#             'S2: {} carbons'.format(chainlengths[0]): nematic[0],\n",
    "#             'S2: {} carbons'.format(chainlengths[1]): nematic[1],\n",
    "#             'S2: {} carbons'.format(chainlengths[2]): nematic[2],\n",
    "#             'S2: {} carbons'.format(chainlengths[3]): nematic[3],\n",
    "#             'S2: {} carbons'.format(chainlengths[4]): nematic[4],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[0]): nematic_err[0],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[1]): nematic_err[1],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[2]): nematic_err[2],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[3]): nematic_err[3],\n",
    "#             'S2 Err: {} carbons'.format(chainlengths[4]): nematic_err[4],\n",
    "#         }\n",
    "#         summary_nematic_25nN_list.append(dict_1)\n",
    "#     summary_nematic_25nN_df = pd.DataFrame(summary_nematic_25nN_list)\n",
    "#     cols = list(summary_nematic_25nN_df.columns)\n",
    "#     cols = ['System', 'S2: 5 carbons', 'S2: 8 carbons',\n",
    "#             'S2: 11 carbons', 'S2: 14 carbons', 'S2: 17 carbons',\n",
    "#             'S2 Err: 5 carbons', 'S2 Err: 8 carbons',\n",
    "#             'S2 Err: 11 carbons', 'S2 Err: 14 carbons', 'S2 Err: 17 carbons']\n",
    "#     summary_nematic_25nN_df = summary_nematic_25nN_df[cols]\n",
    "    \n",
    "#     #print(summary_adhesion_df)\n",
    "#     summary_nematic_25nN_df.to_csv(\"same_terminal_groups_25nN_nematic_summary.csv\")\n",
    "#     summary_nematic_25nN_df.to_html(\"same_terminal_groups_25nN_nematic_summary.html\")\n",
    "#     print(summary_nematic_25nN_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_summary_tribo(old_screening_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate complete prediction of phenol and toluene systems vs the original 16 chemsitries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_old['Terminal Group 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_old['Terminal Group 2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_new_old_df = df_new_old[\n",
    "    (df_new_old['Terminal Group 2'] == 'toluene') | \n",
    "    (df_new_old['Terminal Group 2'] == 'phenol') & \n",
    "    (df_new_old['Terminal Group 1'] != 'phenol') & \n",
    "    (df_new_old['Terminal Group 1'] != 'difluoromethyl') &\n",
    "    (df_new_old['Terminal Group 2'] != 'difluoromethyl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_new_old_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a complete summary of the prediction of the various monolayers\n",
    "# note, this data also exists in a csv file\n",
    "# this takes some time to run\n",
    "\n",
    "# summary_stat = []\n",
    "# for seed in [43, 0, 1, 2, 3]:\n",
    "#     print(seed)\n",
    "#     for smi1 in list(filtered_new_old_df['SMILES-1-H'].unique()):\n",
    "#         for smi2 in list(filtered_new_old_df['SMILES-2-H'].unique()):\n",
    "#             a = rf.predict(SMILES1=smi1,\n",
    "#                        SMILES2=smi2,\n",
    "#                        path_to_data=\".\",\n",
    "#                        random_seed=seed,\n",
    "#                        vary_descriptors=False,\n",
    "#                        vary_significant=False,\n",
    "#                        barcode_seed=123,\n",
    "#                        feature_cluster_json_location=\"./random_forest_tg/\")\n",
    "#             a['SMI-H-TOP'] = smi1\n",
    "#             a['SMI-H-BOTTOM'] = smi2\n",
    "#             a['Terminal Group 1'] = my_inverted_dict[smi1][0]\n",
    "#             a['Terminal Group 2'] = my_inverted_dict[smi2][0]\n",
    "#             summary_stat.append(a)\n",
    "#     #summary_stat_cof.append(a['COF'])\n",
    "#     #summary_stat_intercept.append(a['intercept'])\n",
    "# #print(summary_stat_cof, summary_stat_intercept)\n",
    "# pd.DataFrame(summary_stat)\n",
    "#\n",
    "# summary_new_with_old_df = pd.DataFrame(summary_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_total_list = []\n",
    "# for smi1 in list(summary_new_with_old_df['SMI-H-TOP'].unique()):\n",
    "#     for smi2 in list(summary_new_with_old_df['SMI-H-BOTTOM'].unique()):\n",
    "#         cof_mean = summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['COF'].mean()\n",
    "#         cof_std = summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['COF'].std()\n",
    "#         intercept_mean = summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['intercept'].mean()\n",
    "#         intercept_std = summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['intercept'].std()\n",
    "        \n",
    "#         calc_cof_mean = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi1) & (filtered_new_old_df['SMILES-2-H'] == smi2)]['COF'].mean()\n",
    "#         calc_cof_std = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi1) & (filtered_new_old_df['SMILES-2-H'] == smi2)]['COF'].std()\n",
    "#         calc_intercept_mean = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi1) & (filtered_new_old_df['SMILES-2-H'] == smi2)]['intercept'].mean()\n",
    "#         calc_intercept_std = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi1) & (filtered_new_old_df['SMILES-2-H'] == smi2)]['intercept'].std()\n",
    "#         print(np.any(np.isnan([calc_cof_mean, calc_cof_std, calc_intercept_mean, calc_intercept_std])))\n",
    "#         if np.any(np.isnan([calc_cof_mean, calc_cof_std, calc_intercept_mean, calc_intercept_std])):\n",
    "#             calc_cof_mean = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi2) & (filtered_new_old_df['SMILES-2-H'] == smi1)]['COF'].mean()\n",
    "#             calc_cof_std = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi2) & (filtered_new_old_df['SMILES-2-H'] == smi1)]['COF'].std()\n",
    "#             calc_intercept_mean = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi2) & (filtered_new_old_df['SMILES-2-H'] == smi1)]['intercept'].mean()\n",
    "#             calc_intercept_std = filtered_new_old_df[(filtered_new_old_df['SMILES-1-H'] == smi2) & (filtered_new_old_df['SMILES-2-H'] == smi1)]['intercept'].std()\n",
    "#             summary_total_list.append({\n",
    "#                 'SMI-H-1': smi2,\n",
    "#                 'SMI-H-2': smi1,\n",
    "#                 'Terminal Group 1': summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['Terminal Group 1'].unique()[0],\n",
    "#                 'Terminal Group 2': summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['Terminal Group 2'].unique()[0],\n",
    "#                 'COF Prediction (mean)': cof_mean,\n",
    "#                 'COF Prediction (std)': cof_std,\n",
    "#                 'F0 Prediction (mean)': intercept_mean,\n",
    "#                 'F0 Prediction (std)': intercept_std,\n",
    "#                 'COF Calculated (mean)': calc_cof_mean,\n",
    "#                 'COF Calculated (std)': calc_cof_std,\n",
    "#                 'F0 Calculated (mean)': calc_intercept_mean,\n",
    "#                 'F0 Calculated (std)': calc_intercept_std,\n",
    "#             })\n",
    "#         else:\n",
    "#             summary_total_list.append({\n",
    "#                 'SMI-H-1': smi1,\n",
    "#                 'SMI-H-2': smi2,\n",
    "#                 'Terminal Group 1': summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['Terminal Group 1'].unique()[0],\n",
    "#                 'Terminal Group 2': summary_new_with_old_df[(summary_new_with_old_df['SMI-H-TOP'] == smi1) & (summary_new_with_old_df['SMI-H-BOTTOM'] == smi2)]['Terminal Group 2'].unique()[0],\n",
    "#                 'COF Prediction (mean)': cof_mean,\n",
    "#                 'COF Prediction (std)': cof_std,\n",
    "#                 'F0 Prediction (mean)': intercept_mean,\n",
    "#                 'F0 Prediction (std)': intercept_std,\n",
    "#                 'COF Calculated (mean)': calc_cof_mean,\n",
    "#                 'COF Calculated (std)': calc_cof_std,\n",
    "#                 'F0 Calculated (mean)': calc_intercept_mean,\n",
    "#                 'F0 Calculated (std)': calc_intercept_std,\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(summary_total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_new_old_df[(filtered_new_old_df['Terminal Group 2'] == 'phenol') | (filtered_new_old_df['Terminal Group 1']=='pyrrole')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.DataFrame(summary_total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = list(final_df.columns)\n",
    "# print(col_list)\n",
    "# col_list = ['Terminal Group 1',\n",
    "#             'Terminal Group 2',\n",
    "#             'COF Calculated (mean)',\n",
    "#             'COF Calculated (std)',\n",
    "#             'COF Prediction (mean)',\n",
    "#             'COF Prediction (std)',\n",
    "#             'F0 Calculated (mean)',\n",
    "#             'F0 Calculated (std)',\n",
    "#             'F0 Prediction (mean)',\n",
    "#             'F0 Prediction (std)',\n",
    "#             'SMI-H-1',\n",
    "#             'SMI-H-2',]\n",
    "# final_df = final_df[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#\n",
    "# final_df.sort_values(by='Terminal Group 1').dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two rows had to be dropped, missing data on:\n",
    "\n",
    "1. pyrrole-phenol\n",
    "2. phenyl-phenol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv('two_new_groups_predicted_vs_calculated.csv',)\n",
    "# final_df.to_html('two_new_groups_predicted_vs_calculated.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.read_csv('./csv_files/two_new_groups_predicted_vs_calculated.csv')\n",
    "f_df['COF Calculated (mean)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = f_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df.sort_values(by='Terminal Group 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = f_df.plot(kind='scatter',\n",
    "          x='COF Prediction (mean)',\n",
    "          y='COF Calculated (mean)',\n",
    "          xticks=[0.10, 0.14, 0.18],\n",
    "          yticks=[0.10, 0.14, 0.18]\n",
    "          )\n",
    "X_plot = np.linspace(0.08,0.19,100)\n",
    "ax.set_xlabel('COF (Predicted)')\n",
    "ax.set_ylabel('COF (actual)')\n",
    "ax.plot(X_plot, X_plot,'k',zorder=-1)\n",
    "ax.axis(xmin=0.1, xmax=0.19, ymin=0.1, ymax=0.19)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./cof_pred_calc.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = f_df.plot(kind='scatter',\n",
    "          y='F0 Prediction (mean)',\n",
    "          x='F0 Calculated (mean)',\n",
    "          xticks=[0, 3, 6],\n",
    "          yticks=[0, 3, 6]\n",
    "          )\n",
    "X_plot = np.linspace(0,7,100)\n",
    "ax.set_xlabel('$F_0$ (Predicted)')\n",
    "ax.set_ylabel('$F_0$ (actual)')\n",
    "ax.plot(X_plot, X_plot,'k',zorder=-1)\n",
    "ax.axis(xmin=0, xmax=7, ymin=0, ymax=7)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./intercept_pred_calc.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Prediction (mean)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Calculated (mean)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.axisbelow'] = True\n",
    "hfont = {'fontname':'Helvetica'}\n",
    "X_plot = np.linspace(0,.2,100)\n",
    "plt.errorbar(x=f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Prediction (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Calculated (mean)'],\n",
    "            xerr=f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Prediction (std)'],\n",
    "            yerr=f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Calculated (std)'],\n",
    "            mec='k',\n",
    "            ls='none',\n",
    "            elinewidth=0.75,\n",
    "            marker='o',\n",
    "            fillstyle='full',\n",
    "            c='k',\n",
    "            label='toluene',\n",
    "            alpha=1,\n",
    "            zorder=2)\n",
    "plt.errorbar(x=f_df[(f_df['Terminal Group 2'] == 'phenol')]['COF Prediction (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'phenol')]['COF Calculated (mean)'],\n",
    "            xerr=f_df[(f_df['Terminal Group 2'] == 'phenol')]['COF Prediction (std)'],\n",
    "            yerr=f_df[(f_df['Terminal Group 2'] == 'phenol')]['COF Calculated (std)'],\n",
    "            mec='r',\n",
    "            ls='none',\n",
    "            marker='s',\n",
    "            fillstyle='none',\n",
    "            c='r',\n",
    "            elinewidth=0.75,\n",
    "            label='phenol',\n",
    "            alpha=1,\n",
    "            zorder=2)\n",
    "plt.xticks([0.10, 0.14, 0.18])\n",
    "plt.yticks([0.10, 0.14, 0.18])\n",
    "plt.axis(xmin=0.1, xmax=0.19, ymin=0.1, ymax=0.19)\n",
    "plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "plt.grid(which='all')\n",
    "plt.xlabel('COF (predicted)', **hfont)\n",
    "plt.ylabel('COF (actual)', **hfont)\n",
    "#plt.legend(bbox_to_anchor=(1.04, 1))\n",
    "plt.tight_layout()\n",
    "plt.axes().set_aspect('equal',)\n",
    "#plt.savefig('./cof_pred_calc.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.axisbelow'] = True\n",
    "hfont = {'fontname':'Helvetica'}\n",
    "X_plot = np.linspace(0,7,100)\n",
    "plt.errorbar(x=f_df[(f_df['Terminal Group 2'] == 'toluene')]['F0 Prediction (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'toluene')]['F0 Calculated (mean)'],\n",
    "            xerr=f_df[(f_df['Terminal Group 2'] == 'toluene')]['F0 Prediction (std)'],\n",
    "            yerr=f_df[(f_df['Terminal Group 2'] == 'toluene')]['F0 Calculated (std)'],\n",
    "            ls='none',\n",
    "            elinewidth=0.75,\n",
    "            mec='k',\n",
    "            c='k',\n",
    "            marker='o',\n",
    "            fillstyle='full',\n",
    "            label='toluene',\n",
    "            alpha=1,\n",
    "            zorder=2)\n",
    "plt.errorbar(x=f_df[(f_df['Terminal Group 2'] == 'phenol')]['F0 Prediction (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'phenol')]['F0 Calculated (mean)'],\n",
    "            xerr=f_df[(f_df['Terminal Group 2'] == 'phenol')]['F0 Prediction (std)'],\n",
    "            yerr=f_df[(f_df['Terminal Group 2'] == 'phenol')]['F0 Calculated (std)'],\n",
    "            ls='none',\n",
    "            elinewidth=0.75,\n",
    "            mec='r',\n",
    "            marker='s',\n",
    "            fillstyle='none',\n",
    "            c='r',\n",
    "            alpha=1,\n",
    "            label='phenol',\n",
    "            zorder=2)\n",
    "plt.xticks([0, 3, 6])\n",
    "plt.yticks([0, 3, 6])\n",
    "plt.axis(xmin=0, xmax=7, ymin=0, ymax=7)\n",
    "plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "plt.grid(which='all')\n",
    "plt.xlabel('$F_0$ (predicted), nN')\n",
    "plt.ylabel('$F_0$ (actual), nN')\n",
    "plt.axes().set_aspect(aspect='equal')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./intercept_pred_calc.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.axisbelow'] = True\n",
    "hfont = {'fontname':'Helvetica'}\n",
    "#X_plot = np.linspace(0,7,100)\n",
    "plt.errorbar(x=f_df[(f_df['Terminal Group 2'] == 'toluene')]['F0 Calculated (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Calculated (mean)'],\n",
    "            marker='o',\n",
    "            ls='none',\n",
    "            c='#1f77b4',\n",
    "            alpha=0.9,\n",
    "            elinewidth=0.5,\n",
    "            mec='k',\n",
    "            label='calculated',\n",
    "            zorder=2)\n",
    "plt.errorbar(x=f_df[(f_df['Terminal Group 2'] == 'toluene')]['F0 Prediction (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'toluene')]['COF Prediction (mean)'],\n",
    "            mec='k',\n",
    "            ls='none',\n",
    "            alpha=0.9,\n",
    "            elinewidth=0.5,\n",
    "            marker='o',\n",
    "            c='#d62728',\n",
    "            label='predicted',\n",
    "            zorder=2)\n",
    "plt.yticks([0.10, 0.14, 0.18])\n",
    "plt.xticks([0, 2, 4])\n",
    "plt.axis(xmin=0, xmax=7, ymin=0.10, ymax=0.19)\n",
    "#plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "#plt.legend(loc='best')\n",
    "plt.ylabel('COF')\n",
    "plt.xlabel('$F_0$, nN',fontdict={'fontname': 'Helvetica'})\n",
    "plt.grid(which='all')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./cof_intercept_toluene.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.axisbelow'] = True\n",
    "hfont = {'fontname':'Helvetica'}\n",
    "#X_plot = np.linspace(0,7,100)\n",
    "plt.scatter(x=f_df[(f_df['Terminal Group 2'] == 'phenol')]['F0 Calculated (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'phenol')]['COF Calculated (mean)'],\n",
    "            edgecolors='k',\n",
    "            marker='o',\n",
    "            c='#1f77b4',\n",
    "            label='calculated',\n",
    "            zorder=2)\n",
    "plt.scatter(x=f_df[(f_df['Terminal Group 2'] == 'phenol')]['F0 Prediction (mean)'],\n",
    "            y=f_df[(f_df['Terminal Group 2'] == 'phenol')]['COF Prediction (mean)'],\n",
    "            edgecolors='k',\n",
    "            marker='o',\n",
    "            c='#d62728',\n",
    "            label='predicted',\n",
    "            zorder=2)\n",
    "plt.yticks([0.10, 0.14, 0.18])\n",
    "plt.xticks([0, 3, 6])\n",
    "plt.axis(xmin=0, xmax=7, ymin=0.10, ymax=0.19)\n",
    "#plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('COF')\n",
    "plt.xlabel('$F_0$, nN')\n",
    "plt.grid(which='all')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./cof_intercept_phenol.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old_mixed= []\n",
    "for job in old_mixed_screening_proj:\n",
    "    if \"COF\" in job.document and \"intercept\" in job.document:\n",
    "        data_old_mixed.append({'Terminal Group 1': job.sp['terminal_groups'][0],\n",
    "                         'Terminal Group 2': job.sp['terminal_groups'][1],\n",
    "                         'COF': job.doc['COF'],\n",
    "                         'intercept': job.doc['intercept'],\n",
    "                         'SMILES-1-H': new_smiles_dict[job.sp['terminal_groups'][0]][0],\n",
    "                         'SMILES-2-H': new_smiles_dict[job.sp['terminal_groups'][1]][0]})\n",
    "\n",
    "for job in old_screening_proj:\n",
    "    if \"COF\" in job.document and \"intercept\" in job.document:\n",
    "        data_old_mixed.append({'Terminal Group 1': job.sp['terminal_group'],\n",
    "                         'Terminal Group 2': job.sp['terminal_group'],\n",
    "                         'COF': job.doc['COF'],\n",
    "                         'intercept': job.doc['intercept'],\n",
    "                         'SMILES-1-H': new_smiles_dict[job.sp['terminal_group']][0],\n",
    "                         'SMILES-2-H': new_smiles_dict[job.sp['terminal_group']][0]})\n",
    "        \n",
    "df_previous_study = pd.DataFrame(data_old_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_stat = []\n",
    "# for seed in [43, 0, 1, 2, 3]:\n",
    "#     print(seed)\n",
    "#     for key, smi1 in old_smiles_dict.items(): # list(filtered_new_old_df['SMILES-1-H'].unique()):\n",
    "#         print(smi1)\n",
    "#         for k2, smi2 in old_smiles_dict.items():  #list(filtered_new_old_df['SMILES-2-H'].unique()):\n",
    "#             a = rf.predict(SMILES1=smi1[0],\n",
    "#                        SMILES2=smi2[0],\n",
    "#                        path_to_data=\".\",\n",
    "#                        random_seed=seed,\n",
    "#                        vary_descriptors=False,\n",
    "#                        vary_significant=False,\n",
    "#                        barcode_seed=123,\n",
    "#                        feature_cluster_json_location=\"./random_forest_tg/\")\n",
    "#             a['SMI-H-TOP'] = smi1[0]\n",
    "#             a['SMI-H-BOTTOM'] = smi2[0]\n",
    "#             a['Terminal Group 1'] = my_inverted_dict[smi1[0]][0]\n",
    "#             a['Terminal Group 2'] = my_inverted_dict[smi2[0]][0]\n",
    "#             summary_stat.append(a)\n",
    "# pd.DataFrame(summary_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_train = pd.DataFrame(summary_stat)\n",
    "df_test_train = pd.read_csv('./csv_files/andrew_df_test_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_train[(df_test_train['Terminal Group 1'] == 'perfluoromethyl') \n",
    "                     & (df_test_train['Terminal Group 2'] == 'perfluoromethyl')&\n",
    "                    (df_test_train['Model Number'] == 43)]\n",
    "list(df_test_train['Terminal Group 1'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "summary_project_df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', \"./csv_files/model_*_summary*_*_andrew*.csv\"))),axis=1,).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "summary_project_df = summary_project_df.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "five_models = dict()\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    five_models['model{}'.format(model)] = pd.read_csv('./csv_files/model_{}_summary_test_train_andrew.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_models['model0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_train[ \n",
    "              (df_test_train['Terminal Group 1']=='acetyl') &\n",
    "              (df_test_train['Terminal Group 2'] == 'acetyl')]['COF'].describe()\n",
    "\n",
    "print(sorted(list(df_old_andrew['Terminal Group 1'].unique())))\n",
    "print(sorted(list(df_old_andrew['Terminal Group 2'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_andrew = []\n",
    "for tg1 in list(df_old_andrew['Terminal Group 1'].unique()):\n",
    "    for tg2 in list(df_old_andrew['Terminal Group 2'].unique()):\n",
    "        cof_mean = df_test_train[\n",
    "            (df_test_train['Terminal Group 1'] == tg1) &\n",
    "            (df_test_train['Terminal Group 2'] == tg2)]['COF'].mean()\n",
    "        cof_std = df_test_train[\n",
    "            (df_test_train['Terminal Group 1'] == tg1) &\n",
    "            (df_test_train['Terminal Group 2'] == tg2)]['COF'].std()\n",
    "        intercept_mean = df_test_train[\n",
    "            (df_test_train['Terminal Group 1'] == tg1) &\n",
    "            (df_test_train['Terminal Group 2'] == tg2)]['intercept'].mean()\n",
    "        intercept_std = df_test_train[\n",
    "            (df_test_train['Terminal Group 1'] == tg1) &\n",
    "            (df_test_train['Terminal Group 2'] == tg2)]['intercept'].std()\n",
    "\n",
    "        cof_calc_mean = df_old_andrew[\n",
    "            (df_old_andrew['Terminal Group 1'] == tg1) &\n",
    "            (df_old_andrew['Terminal Group 2'] == tg2)]['COF'].mean()\n",
    "        cof_calc_std = df_old_andrew[\n",
    "            (df_old_andrew['Terminal Group 1'] == tg1) &\n",
    "            (df_old_andrew['Terminal Group 2'] == tg2)]['COF'].std()\n",
    "        intercept_calc_mean = df_old_andrew[\n",
    "            (df_old_andrew['Terminal Group 1'] == tg1) &\n",
    "            (df_old_andrew['Terminal Group 2'] == tg2)]['intercept'].mean()\n",
    "        intercept_calc_std = df_old_andrew[\n",
    "            (df_old_andrew['Terminal Group 1'] == tg1) &\n",
    "            (df_old_andrew['Terminal Group 2'] == tg2)]['intercept'].std()\n",
    "\n",
    "        print(np.any(np.isnan([cof_calc_mean, cof_calc_std, intercept_calc_mean, intercept_calc_std])))\n",
    "        if np.any(np.isnan([cof_calc_mean, cof_calc_std, intercept_calc_mean, intercept_calc_std])):\n",
    "            cof_calc_mean = df_old_andrew[\n",
    "                (df_old_andrew['Terminal Group 1'] == tg2) &\n",
    "                (df_old_andrew['Terminal Group 2'] == tg1)]['COF'].mean()\n",
    "            cof_calc_std = df_old_andrew[\n",
    "                (df_old_andrew['Terminal Group 1'] == tg2) &\n",
    "                (df_old_andrew['Terminal Group 2'] == tg1)]['COF'].std()\n",
    "            intercept_calc_mean = df_old_andrew[\n",
    "                (df_old_andrew['Terminal Group 1'] == tg2) &\n",
    "                (df_old_andrew['Terminal Group 2'] == tg1)]['intercept'].mean()\n",
    "            intercept_calc_std = df_old_andrew[\n",
    "                (df_old_andrew['Terminal Group 1'] == tg2) &\n",
    "                (df_old_andrew['Terminal Group 2'] == tg1)]['intercept'].std()\n",
    "            summary_andrew.append({\n",
    "                'Terminal Group 1': tg1,\n",
    "                'Terminal Group 2': tg2,\n",
    "                'COF Prediction (mean)': cof_mean,\n",
    "                'COF Prediction (std)': cof_std,\n",
    "                'F0 Prediction (mean)': intercept_mean,\n",
    "                'F0 Prediction (std)': intercept_std,\n",
    "                'COF Calculated (mean)': cof_calc_mean,\n",
    "                'COF Calculated (std)': cof_calc_std,\n",
    "                'F0 Calculated (mean)': intercept_calc_mean,\n",
    "                'F0 Calculated (std)': intercept_calc_std,\n",
    "            })\n",
    "        else:\n",
    "            summary_andrew.append({\n",
    "                'Terminal Group 1': tg1,\n",
    "                'Terminal Group 2': tg2,\n",
    "                'COF Prediction (mean)': cof_mean,\n",
    "                'COF Prediction (std)': cof_std,\n",
    "                'F0 Prediction (mean)': intercept_mean,\n",
    "                'F0 Prediction (std)': intercept_std,\n",
    "                'COF Calculated (mean)': cof_calc_mean,\n",
    "                'COF Calculated (std)': cof_calc_std,\n",
    "                'F0 Calculated (mean)': intercept_calc_mean,\n",
    "                'F0 Calculated (std)': intercept_calc_std,\n",
    "            })\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary_andrew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.dropna(how='any')\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_train[(df_test_train['Terminal Group 1'] == tg1) & \n",
    "#                      (df_test_train['Terminal Group 2'] == tg2)&\n",
    "#                      (df_test_train['Model Number'] == 43)]['COF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list_group1 = list(andrew_models['model0']['Terminal Group 1'])\n",
    "model_list_group2 = list(andrew_models['model0']['Terminal Group 2'])\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    plt.clf()\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    hfont = {'fontname':'Helvetica'}\n",
    "    X_plot = np.linspace(0,.3,100)\n",
    "    counter = 0\n",
    "    for tg1, tg2 in zip(model_list_group1, model_list_group2):\n",
    "        model_df = andrew_models['model{}'.format(model)]\n",
    "        counter = counter + 1\n",
    "        if (np.all(model_df[(model_df['Terminal Group 1'] == tg1) & \n",
    "                            (model_df['Terminal Group 2'] == tg2)]['Model {}'.format(model)] == 'Train')):\n",
    "            plt.errorbar(x=df_test_train[(df_test_train['Terminal Group 1'] == tg1) & \n",
    "                             (df_test_train['Terminal Group 2'] == tg2)&\n",
    "                             (df_test_train['Model Number'] == 43)]['COF'],\n",
    "                        y=summary_df[(summary_df['Terminal Group 1'] == tg1) &\n",
    "                                        (summary_df['Terminal Group 2'] == tg2)]['COF Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=summary_df[(summary_df['Terminal Group 1'] == tg1) &\n",
    "                                        (summary_df['Terminal Group 2'] == tg2)]['COF Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.5,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        elinewidth=0.5,\n",
    "                        marker='.',\n",
    "                        ms=7,\n",
    "                        fillstyle='full',\n",
    "                        c='w',\n",
    "                        label='train',\n",
    "                        alpha=1,\n",
    "                        zorder=2)\n",
    "        else:\n",
    "            plt.errorbar(x=df_test_train[(df_test_train['Terminal Group 1'] == tg1) & \n",
    "                             (df_test_train['Terminal Group 2'] == tg2)&\n",
    "                             (df_test_train['Model Number'] == 43)]['COF'],\n",
    "                        y=summary_df[(summary_df['Terminal Group 1'] == tg1) &\n",
    "                                        (summary_df['Terminal Group 2'] == tg2)]['COF Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=summary_df[(summary_df['Terminal Group 1'] == tg1) &\n",
    "                                        (summary_df['Terminal Group 2'] == tg2)]['COF Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.75,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        marker='X',\n",
    "                        fillstyle='full',\n",
    "                        c='r',\n",
    "                        ms=4,\n",
    "                        elinewidth=0.75,\n",
    "                        label='test',\n",
    "                        alpha=1,\n",
    "                        zorder=3)\n",
    "    plt.xticks([0.08, 0.14, 0.18])\n",
    "    plt.yticks([0.08, 0.14, 0.18])\n",
    "    plt.axis(xmin=0.08, xmax=0.21, ymin=0.08, ymax=0.21)\n",
    "    plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "    plt.grid(which='all')\n",
    "    plt.xlabel('COF (predicted)', **hfont)\n",
    "    plt.ylabel('COF (actual)', **hfont)\n",
    "    plt.tight_layout()\n",
    "    plt.axes().set_aspect('equal',)\n",
    "    plt.savefig('./cof_test_train_andrew_model_{}.pdf'.format(model), format='pdf')\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list_group1 = list(andrew_models['model0']['Terminal Group 1'])\n",
    "model_list_group2 = list(andrew_models['model0']['Terminal Group 2'])\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    plt.clf()\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    hfont = {'fontname':'Helvetica'}\n",
    "    X_plot = np.linspace(0,7,100)\n",
    "    counter = 0\n",
    "    for tg1, tg2 in zip(model_list_group1, model_list_group2):\n",
    "        model_df = andrew_models['model{}'.format(model)]\n",
    "        if (np.all(model_df[(model_df['Terminal Group 1'] == tg1) & \n",
    "                            (model_df['Terminal Group 2'] == tg2)]['Model {}'.format(model)] == 'Train')):\n",
    "            plt.errorbar(x=andrew_df_test_train[(andrew_df_test_train['Terminal Group 1'] == tg1) & \n",
    "                             (andrew_df_test_train['Terminal Group 2'] == tg2)&\n",
    "                             (andrew_df_test_train['Model Number'] == model)]['intercept'],\n",
    "                        y=and_summar_df[(and_summar_df['Terminal Group 1'] == tg1) &\n",
    "                                        (and_summar_df['Terminal Group 2'] == tg2)]['F0 Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=and_summar_df[(and_summar_df['Terminal Group 1'] == tg1) &\n",
    "                                        (and_summar_df['Terminal Group 2'] == tg2)]['F0 Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.5,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        elinewidth=0.5,\n",
    "                        marker='.',\n",
    "                        ms=7,\n",
    "                        fillstyle='full',\n",
    "                        c='w',\n",
    "                        label='train',\n",
    "                        alpha=1,\n",
    "                        zorder=2)\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "            plt.errorbar(x=andrew_df_test_train[(andrew_df_test_train['Terminal Group 1'] == tg1) & \n",
    "                             (andrew_df_test_train['Terminal Group 2'] == tg2)&\n",
    "                             (andrew_df_test_train['Model Number'] == model)]['intercept'],\n",
    "                        y=and_summar_df[(and_summar_df['Terminal Group 1'] == tg1) &\n",
    "                                        (and_summar_df['Terminal Group 2'] == tg2)]['F0 Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=and_summar_df[(and_summar_df['Terminal Group 1'] == tg1) &\n",
    "                                        (and_summar_df['Terminal Group 2'] == tg2)]['F0 Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.75,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        marker='X',\n",
    "                        fillstyle='full',\n",
    "                        c='r',\n",
    "                        ms=4,\n",
    "                        elinewidth=0.75,\n",
    "                        label='test',\n",
    "                        alpha=1,\n",
    "                        zorder=3)\n",
    "    plt.xticks([0, 3, 6])\n",
    "    plt.yticks([0, 3, 6])\n",
    "    plt.axis(xmin=0, xmax=7, ymin=0, ymax=7)\n",
    "    plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "    plt.grid(which='all')\n",
    "    plt.xlabel('$F_0$ (predicted), nN')\n",
    "    plt.ylabel('$F_0$ (actual), nN')\n",
    "    plt.tight_layout()\n",
    "    plt.axes().set_aspect('equal',)\n",
    "    #plt.savefig('./intercept_test_train_andrew_model_{}.pdf'.format(model), format='pdf')\n",
    "    #print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile generate_plots.py\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load in the relevant dataframes\n",
    "screening_original_df = pd.read_csv('./csv_files/monolayer_screening_original_data.csv')\n",
    "test_train_df = pd.read_csv('./csv_files/andrew_df_test_train.csv')\n",
    "\n",
    "summary_model_df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', \"./csv_files/model_*_summary*_*_andrew*.csv\"))),axis=1,).drop_duplicates().reset_index(drop=True)\n",
    "summary_model_df = summary_model_df.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "orig_models = dict()\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    orig_models['model{}'.format(model)] = pd.read_csv('./csv_files/model_{}_summary_test_train_andrew.csv'.format(model))\n",
    "\n",
    "# generate summary of simulation data from original projects\n",
    "summary_project = []\n",
    "for tg1 in list(screening_original_df['Terminal Group 1'].unique()):\n",
    "    for tg2 in list(screening_original_df['Terminal Group 2'].unique()):\n",
    "        cof_mean = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['COF'].mean()\n",
    "        cof_std = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['COF'].std()\n",
    "        intercept_mean = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['intercept'].mean()\n",
    "        intercept_std = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['intercept'].std()\n",
    "\n",
    "        cof_calc_mean = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['COF'].mean()\n",
    "        cof_calc_std = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['COF'].std()\n",
    "        intercept_calc_mean = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['intercept'].mean()\n",
    "        intercept_calc_std = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['intercept'].std()\n",
    "\n",
    "        print(np.any(np.isnan([cof_calc_mean, cof_calc_std, intercept_calc_mean, intercept_calc_std])))\n",
    "        if np.any(np.isnan([cof_calc_mean, cof_calc_std, intercept_calc_mean, intercept_calc_std])):\n",
    "            cof_calc_mean = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['COF'].mean()\n",
    "            cof_calc_std = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['COF'].std()\n",
    "            intercept_calc_mean = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['intercept'].mean()\n",
    "            intercept_calc_std = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['intercept'].std()\n",
    "            summary_project.append({\n",
    "                'Terminal Group 1': tg1,\n",
    "                'Terminal Group 2': tg2,\n",
    "                'COF Prediction (mean)': cof_mean,\n",
    "                'COF Prediction (std)': cof_std,\n",
    "                'F0 Prediction (mean)': intercept_mean,\n",
    "                'F0 Prediction (std)': intercept_std,\n",
    "                'COF Calculated (mean)': cof_calc_mean,\n",
    "                'COF Calculated (std)': cof_calc_std,\n",
    "                'F0 Calculated (mean)': intercept_calc_mean,\n",
    "                'F0 Calculated (std)': intercept_calc_std,\n",
    "            })\n",
    "        else:\n",
    "            summary_project.append({\n",
    "                'Terminal Group 1': tg1,\n",
    "                'Terminal Group 2': tg2,\n",
    "                'COF Prediction (mean)': cof_mean,\n",
    "                'COF Prediction (std)': cof_std,\n",
    "                'F0 Prediction (mean)': intercept_mean,\n",
    "                'F0 Prediction (std)': intercept_std,\n",
    "                'COF Calculated (mean)': cof_calc_mean,\n",
    "                'COF Calculated (std)': cof_calc_std,\n",
    "                'F0 Calculated (mean)': intercept_calc_mean,\n",
    "                'F0 Calculated (std)': intercept_calc_std,\n",
    "            })\n",
    "# convert list of dictionaries into dataframe, drop any NaN values\n",
    "project_pred_calc_df = pd.DataFrame(summary_project).dropna(how='any')\n",
    "\n",
    "\n",
    "# now generate COF Test/Train Plots\n",
    "\n",
    "model_list_group1 = list(orig_models['model0']['Terminal Group 1'])\n",
    "model_list_group2 = list(orig_models['model0']['Terminal Group 2'])\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    plt.clf()\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    hfont = {'fontname':'Helvetica'}\n",
    "    X_plot = np.linspace(0,.3,100)\n",
    "    for tg1, tg2 in zip(model_list_group1, model_list_group2):\n",
    "        model_df = orig_models['model{}'.format(model)]\n",
    "        # check if this datum was for testing or training\n",
    "        if (np.all(model_df[(model_df['Terminal Group 1'] == tg1) & \n",
    "                            (model_df['Terminal Group 2'] == tg2)]['Model {}'.format(model)] == 'Train')):\n",
    "            plt.errorbar(x=test_train_df[(test_train_df['Terminal Group 1'] == tg1) & \n",
    "                             (test_train_df['Terminal Group 2'] == tg2) &\n",
    "                             (test_train_df['Model Number'] == model)]['COF'],\n",
    "                        y=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['COF Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['COF Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.5,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        elinewidth=0.5,\n",
    "                        marker='.',\n",
    "                        ms=7,\n",
    "                        fillstyle='full',\n",
    "                        c='w',\n",
    "                        label='train',\n",
    "                        alpha=1,\n",
    "                        zorder=2)\n",
    "        else:\n",
    "            plt.errorbar(x=test_train_df[(test_train_df['Terminal Group 1'] == tg1) & \n",
    "                             (test_train_df['Terminal Group 2'] == tg2)&\n",
    "                             (test_train_df['Model Number'] == model)]['COF'],\n",
    "                        y=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['COF Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['COF Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.75,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        marker='X',\n",
    "                        fillstyle='full',\n",
    "                        c='r',\n",
    "                        ms=4,\n",
    "                        elinewidth=0.75,\n",
    "                        label='test',\n",
    "                        alpha=1,\n",
    "                        zorder=3)\n",
    "    plt.xticks([0.08, 0.14, 0.18])\n",
    "    plt.yticks([0.08, 0.14, 0.18])\n",
    "    plt.axis(xmin=0.08, xmax=0.21, ymin=0.08, ymax=0.21)\n",
    "    plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "    plt.grid(which='all')\n",
    "    plt.xlabel('COF (predicted)', **hfont)\n",
    "    plt.ylabel('COF (actual)', **hfont)\n",
    "    plt.tight_layout()\n",
    "    plt.axes().set_aspect('equal',)\n",
    "    plt.savefig('./cof_test_train_andrew_model_{}.pdf'.format(model), format='pdf')\n",
    "    \n",
    "    \n",
    "# now generate F0 test/train plots\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    plt.clf()\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    hfont = {'fontname':'Helvetica'}\n",
    "    X_plot = np.linspace(0,7,100)\n",
    "    for tg1, tg2 in zip(model_list_group1, model_list_group2):\n",
    "        model_df = orig_models['model{}'.format(model)]\n",
    "        # check if this datum was for testing or training\n",
    "        if (np.all(model_df[(model_df['Terminal Group 1'] == tg1) & \n",
    "                            (model_df['Terminal Group 2'] == tg2)]['Model {}'.format(model)] == 'Train')):\n",
    "            plt.errorbar(x=test_train_df[(test_train_df['Terminal Group 1'] == tg1) & \n",
    "                             (test_train_df['Terminal Group 2'] == tg2) &\n",
    "                             (test_train_df['Model Number'] == model)]['intercept'],\n",
    "                        y=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['F0 Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['F0 Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.5,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        elinewidth=0.5,\n",
    "                        marker='.',\n",
    "                        ms=7,\n",
    "                        fillstyle='full',\n",
    "                        c='w',\n",
    "                        label='train',\n",
    "                        alpha=1,\n",
    "                        zorder=2)\n",
    "        else:\n",
    "            plt.errorbar(x=test_train_df[(test_train_df['Terminal Group 1'] == tg1) & \n",
    "                             (test_train_df['Terminal Group 2'] == tg2)&\n",
    "                             (test_train_df['Model Number'] == model)]['intercept'],\n",
    "                        y=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['F0 Calculated (mean)'],\n",
    "                        xerr=None,\n",
    "                        yerr=project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) &\n",
    "                                        (project_pred_calc_df['Terminal Group 2'] == tg2)]['F0 Calculated (std)'],\n",
    "                        mec='k',\n",
    "                        mew=0.75,\n",
    "                        ecolor='k',\n",
    "                        ls='none',\n",
    "                        marker='X',\n",
    "                        fillstyle='full',\n",
    "                        c='r',\n",
    "                        ms=4,\n",
    "                        elinewidth=0.75,\n",
    "                        label='test',\n",
    "                        alpha=1,\n",
    "                        zorder=3)\n",
    "    plt.xticks([0, 3, 6])\n",
    "    plt.yticks([0, 3, 6])\n",
    "    plt.axis(xmin=0, xmax=7, ymin=0, ymax=7)\n",
    "    plt.plot(X_plot, X_plot,'k',zorder=1)\n",
    "    plt.grid(which='all')\n",
    "    plt.xlabel('$F_0$ (predicted), nN')\n",
    "    plt.ylabel('$F_0$ (actual), nN')\n",
    "    plt.tight_layout()\n",
    "    plt.axes().set_aspect('equal',)\n",
    "    plt.savefig('./intercept_test_train_andrew_model_{}.pdf'.format(model), format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_original_df = pd.read_csv('./csv_files/monolayer_screening_original_data.csv')\n",
    "test_train_df = pd.read_csv('./csv_files/andrew_df_test_train.csv')\n",
    "orig_models = dict()\n",
    "for model in [43, 0, 1, 2, 3]:\n",
    "    orig_models['model{}'.format(model)] = pd.read_csv('./csv_files/model_{}_summary_test_train_andrew.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate summary of simulation data from original projects\n",
    "summary_project = []\n",
    "for tg1 in list(screening_original_df['Terminal Group 1'].unique()):\n",
    "    for tg2 in list(screening_original_df['Terminal Group 2'].unique()):\n",
    "        cof_mean = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['COF'].mean()\n",
    "        cof_std = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['COF'].std()\n",
    "        intercept_mean = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['intercept'].mean()\n",
    "        intercept_std = test_train_df[\n",
    "            (test_train_df['Terminal Group 1'] == tg1) &\n",
    "            (test_train_df['Terminal Group 2'] == tg2)]['intercept'].std()\n",
    "\n",
    "        cof_calc_mean = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['COF'].mean()\n",
    "        cof_calc_std = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['COF'].std()\n",
    "        intercept_calc_mean = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['intercept'].mean()\n",
    "        intercept_calc_std = screening_original_df[\n",
    "            (screening_original_df['Terminal Group 1'] == tg1) &\n",
    "            (screening_original_df['Terminal Group 2'] == tg2)]['intercept'].std()\n",
    "\n",
    "        print(np.any(np.isnan([cof_calc_mean, cof_calc_std, intercept_calc_mean, intercept_calc_std])))\n",
    "        if np.any(np.isnan([cof_calc_mean, cof_calc_std, intercept_calc_mean, intercept_calc_std])):\n",
    "            cof_calc_mean = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['COF'].mean()\n",
    "            cof_calc_std = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['COF'].std()\n",
    "            intercept_calc_mean = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['intercept'].mean()\n",
    "            intercept_calc_std = screening_original_df[\n",
    "                (screening_original_df['Terminal Group 1'] == tg2) &\n",
    "                (screening_original_df['Terminal Group 2'] == tg1)]['intercept'].std()\n",
    "            summary_project.append({\n",
    "                'Terminal Group 1': tg1,\n",
    "                'Terminal Group 2': tg2,\n",
    "                'COF Prediction (mean)': cof_mean,\n",
    "                'COF Prediction (std)': cof_std,\n",
    "                'F0 Prediction (mean)': intercept_mean,\n",
    "                'F0 Prediction (std)': intercept_std,\n",
    "                'COF Calculated (mean)': cof_calc_mean,\n",
    "                'COF Calculated (std)': cof_calc_std,\n",
    "                'F0 Calculated (mean)': intercept_calc_mean,\n",
    "                'F0 Calculated (std)': intercept_calc_std,\n",
    "            })\n",
    "        else:\n",
    "            summary_project.append({\n",
    "                'Terminal Group 1': tg1,\n",
    "                'Terminal Group 2': tg2,\n",
    "                'COF Prediction (mean)': cof_mean,\n",
    "                'COF Prediction (std)': cof_std,\n",
    "                'F0 Prediction (mean)': intercept_mean,\n",
    "                'F0 Prediction (std)': intercept_std,\n",
    "                'COF Calculated (mean)': cof_calc_mean,\n",
    "                'COF Calculated (std)': cof_calc_std,\n",
    "                'F0 Calculated (mean)': intercept_calc_mean,\n",
    "                'F0 Calculated (std)': intercept_calc_std,\n",
    "            })\n",
    "# convert list of dictionaries into dataframe, drop any NaN values\n",
    "project_pred_calc_df = pd.DataFrame(summary_project).dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_pred_calc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_list = list()\n",
    "model_list_group1 = list(orig_models['model0']['Terminal Group 1'])\n",
    "model_list_group2 = list(orig_models['model0']['Terminal Group 2'])\n",
    "for tg1, tg2 in zip(model_list_group1, model_list_group2):\n",
    "    print(project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) & (project_pred_calc_df['Terminal Group 2'] == tg2)])\n",
    "    my_new_list.append(project_pred_calc_df[(project_pred_calc_df['Terminal Group 1'] == tg1) & (project_pred_calc_df['Terminal Group 2'] == tg2)])\n",
    "    \n",
    "my_new_df = pd.concat(my_new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
